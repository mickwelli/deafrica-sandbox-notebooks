{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WOfS Validation Data Analysis - Window-based  <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">\n",
    "\n",
    "* **Products used:** \n",
    "[ga_ls8c_wofs_2](https://explorer.digitalearth.africa/ga_ls8c_wofs_2),\n",
    "[ga_ls8c_wofs_2_summary ](https://explorer.digitalearth.africa/ga_ls8c_wofs_2_summary) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The [Water Observations from Space (WOfS)](https://www.ga.gov.au/scientific-topics/community-safety/flood/wofs/about-wofs) is a derived product from Landsat 8 satellite observations as part of provisional Landsat 8 Collection 2 surface reflectance and shows surface water detected in Africa.\n",
    "Individual water classified images are called Water Observation Feature Layers (WOFLs), and are created in a 1-to-1 relationship with the input satellite data. \n",
    "Hence there is one WOFL for each satellite dataset processed for the occurrence of water.\n",
    "\n",
    "The data in a WOFL is stored as a bit field. This is a binary number, where each digit of the number is independantly set or not based on the presence (1) or absence (0) of a particular attribute (water, cloud, cloud shadow etc). In this way, the single decimal value associated to each pixel can provide information on a variety of features of that pixel. \n",
    "For more information on the structure of WOFLs and how to interact with them, see [Water Observations from Space](../Datasets/Water_Observations_from_Space.ipynb) and [Applying WOfS bitmasking](../Frequently_used_code/Applying_WOfS_bitmasking.ipynb) notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook explains how you can perform validation analysis for WOFS derived product using collected ground truth dataset and window-based sampling. \n",
    "\n",
    "The notebook demonstrates how to:\n",
    "\n",
    "1. Load validation points for each partner institutions following cleaning stage as an ESRI shapefile\n",
    "2. Query WOFL data for validation points and capture available WOfS observation available\n",
    "3. Extract statistics for each WOfS observation in each validation point using a 3 by 3 window \n",
    "4. Extract a LUT for each point that contains both validation info and WOfS result for each month \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell.\n",
    "\n",
    "After finishing the analysis, you can modify some values in the \"Analysis parameters\" cell and re-run the analysis to load WOFLs for a different location or time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time \n",
    "import datacube\n",
    "from datacube.utils import masking, geometry \n",
    "import sys\n",
    "import os\n",
    "import dask \n",
    "import rasterio, rasterio.features\n",
    "import xarray\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import geopandas as gpd\n",
    "import subprocess as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy, scipy.ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #this will suppress the warnings for multiple UTM zones in your AOI \n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "from rasterio.mask import mask\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from deafrica_plotting import map_shapefile,display_map, rgb\n",
    "from deafrica_spatialtools import xr_rasterize\n",
    "from deafrica_datahandling import wofs_fuser, mostcommon_crs,load_ard,deepcopy\n",
    "from deafrica_dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Activate the datacube database, which provides functionality for loading and displaying stored Earth observation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='WOfS_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse validation points collected by each partner institution, we need to obtain WOfS surface water observation data that corresponds with the labelled input data locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load validation points for each partner institutions as a list of observations each has a location and month\n",
    "    * Load the cleaned validation file as ESRI `shapefile`\n",
    "    * Inspect the shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Supplementary_data/Validation/Refined/groundtruth_RCMRD.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = gpd.read_file(path).to_crs('epsg:6933') #reading the table and converting CRS to metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data= input_data.drop(['Unnamed_ 0','Unnamed__1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [(x,y) for x, y in zip(input_data.geometry.x, input_data.geometry.y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample WOfS at the ground truth coordinates in 3 by 3 window size\n",
    "To load WOFL data, we can first create a re-usable query as below that will define the time period we are interested in, as well as other important parameters that are used to correctly load the data. \n",
    "\n",
    "As WOFLs are created scene-by-scene, and some scenes overlap, it's important when loading data to `group_by` solar day, and ensure that the data between scenes is combined correctly by using the WOfS `fuse_func`.\n",
    "This will merge observations taken on the same day, and ensure that important data isn't lost when overlapping datasets are combined.\n",
    "\n",
    "We can convert the WOFL bit field into a binary array containing True and False values. This allows us to use the WOFL data as a mask that can be applied to other datasets.\n",
    "The `make_mask` function allows us to create a mask using the flag labels (e.g. \"wet\" or \"dry\") rather than the binary numbers we used above. For more details on how to do masking on WOfS, see the [Applying_WOfS_bit_masking](../Frequently_used_code/Applying_WOfS_bitmasking.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate query object \n",
    "#need to rethink the items x and y for the coordinates \n",
    "query ={'group_by':'solar_day',\n",
    "        'resampling':'nearest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Step 1: update the query for WOfS based on CEO input table \n",
    "for index, row in input_data.iterrows():  \n",
    "    #get the month value for each index\n",
    "    month = input_data.loc[index]['MONTH'] \n",
    "    #set the time for query of the WOfS database according to the month value in the validation table \n",
    "    time = '2018-' + f'{month:02d}' \n",
    "    #this is for having the original query as it is \n",
    "    dc_query = deepcopy(query) \n",
    "    geom = geometry.Geometry(input_data.geometry.values[index].__geo_interface__,  geometry.CRS('EPSG:6933'))\n",
    "    q = {\"geopolygon\":geom}\n",
    "    t = {\"time\":time} \n",
    "    dc_query.update(t)\n",
    "    dc_query.update(q)\n",
    "    wofls = dc.load(product =\"ga_ls8c_wofs_2\", y = (input_data.geometry.y[index] - 30.5, input_data.geometry.y[index] + 30.5), x =(input_data.geometry.x[index] - 30.5, input_data.geometry.x[index] + 30.5),\n",
    "                    crs = 'EPSG:6933',time=time, output_crs = 'EPSG:6933', resolution=(-30,30))\n",
    "    \n",
    "##Test the value of wofs \n",
    "    #print(wofls.isel(time=-1).water.values)\n",
    "##Test the value of wofs \n",
    "    # # Define a mask for wet and clear pixels \n",
    "    wet_nocloud = {\"water_observed\":True, \"cloud_shadow\":False, \"cloud\":False,\"nodata\":False}\n",
    "    # # Define a mask for dry and clear pixels \n",
    "    dry_nocloud = {\"water_observed\":False, \"cloud_shadow\":False, \"cloud\":False, \"nodata\":False}\n",
    "    wofl_wetnocloud = masking.make_mask(wofls, **wet_nocloud).astype(int) \n",
    "    wofl_drynocloud = masking.make_mask(wofls, **dry_nocloud).astype(int)\n",
    "    clear = (wofl_wetnocloud | wofl_drynocloud).water.all(dim=['x','y']).values\n",
    "    n_clear = clear.sum() #record this and use it to filter out month with no valid data \n",
    "    if n_clear > 0:\n",
    "        wet = wofl_wetnocloud.isel(time=clear).water.max().values  #record this as WOfS has seen water in the 3*3 window\n",
    "    else:\n",
    "        wet = 0 \n",
    "    input_data.at[index,'CLASS_WET'] = wet\n",
    "    input_data.at[index,'CLEAR_OBS'] = n_clear\n",
    "    \n",
    "###Test the window size[*use this before masking]\n",
    "    #unique, countx = np.unique(wofls.x.values, return_counts=True)\n",
    "    #unique, county = np.unique(wofls.y.values, return_counts=True)\n",
    "    #print(wofls.x.values)\n",
    "    #input_data.at[index,'X'] = len(countx) #this will add the number of x window to the list of points \n",
    "    #input_data.at[index,'Y'] = len(county) #this will add the number of y window to the list of points \n",
    "###Test the window size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data.to_csv(('../Supplementary_data/Validation/Refined/ground_truth_RCMRD.csv'))\n",
    "input_data.to_csv(('../Supplementary_data/Validation/Refined/validationpoints_w305m.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexNames = (input_data['WATERFLAG'] > 2) & (input_data['CLEAR_OBS'] > 0) & (input_data['FREQUENCY'] > 0) & (input_data['FREQUENCY'] < 1) #that is for or you need to use\n",
    "# indexNames.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell needs to run if you encounter with the large data set (input_data) and overnight running or anything that close the sandbox\n",
    "input_data = pd.read_csv('../Supplementary_data/Validation/Refined/validationpoints_w305m.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as water flag more than 1 and also clear observation equal to zero \n",
    "indexNames = input_data[(input_data['WATERFLAG'] > 1) | (input_data['CLEAR_OBS'] == 0)].index \n",
    "#indexNames\n",
    "input_data.drop(indexNames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLOT_ID\n",
       "137387037.0     7\n",
       "137387038.0     9\n",
       "137387040.0     6\n",
       "137387041.0     5\n",
       "137387042.0     5\n",
       "               ..\n",
       "137387757.0    12\n",
       "137387758.0    11\n",
       "137387759.0    12\n",
       "137387760.0    12\n",
       "137387761.0     8\n",
       "Name: MONTH, Length: 698, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this will count on the number of month for each plotID in the final table \n",
    "count = input_data.groupby(['PLOT_ID'])['MONTH'].count()\n",
    "#count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the check on the count for each plot id as a csv file \n",
    "count.to_csv('../Supplementary_data/Validation/Refined/final_RCMRD_count_window3by3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.to_csv(('../Supplementary_data/Validation/Refined/ground_truth_RCMRD_W305mfinal.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** January 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DE Africa User Guide's [Tags Index](https://) (placeholder as this does not exist yet)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**:  :index:`WOfS`, :index:`fractional cover`, :index:`deafrica_plotting`, :index:`deafrica_datahandling`, :index:`display_map`, :index:`wofs_fuser`, :index:`WOFL`, :index:`masking`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the pandas geo-dataframe to a shapefile and save it \n",
    "#Read in the validation data csv\n",
    "# CEO = '../Supplementary_data/Validation/Refined/CEO_RCMRD_2020-07-30.csv'\n",
    "# df = pd.read_csv(CEO,delimiter=\",\")\n",
    "# geometry = [Point(xy) for xy in zip(df.LON, df.LAT)]\n",
    "# crs = {'init': 'epsg:4326'} \n",
    "# geo_df = GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "# geo_df.to_file(driver='ESRI Shapefile', filename='../Supplementary_data/Validation/Refined/groundtruth_RCMRD.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the validation data points shapefile \n",
    "# GT = gpd.read_file('../Supplementary_data/Validation/Refined/groundtruth_RCMRD.shp')\n",
    "# #reproject the shapefile from EPSG:4326 to match WOfS dataset \n",
    "# ground_truth  = GT.to_crs({'init': 'epsg:6933'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '../Supplementary_data/Validation/subset_clip.shp'\n",
    "#path = '../Supplementary_data/Validation/Refined/groundtruth_RCMRD.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "9e3fa49adf8c4170abfcd954c2ec045a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "dc642f11c1fb492ca419b0ed6fc4f8c3": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
