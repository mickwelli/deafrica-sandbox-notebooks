{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Validation Dataset <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The [Water Observations from Space (WOfS)](https://www.ga.gov.au/scientific-topics/community-safety/flood/wofs/about-wofs) is a derived product from Landsat-8 satellite observations as part of provisional Landsat 8 Collection 2 surface reflectance and shows surface water detected in Africa. Prior to conduct accuracy assessment for Water Observations from Space in Africa, it can be useful to inpsect the validation points each partner institutions in Africa explored and classified as `water`, `no water`, `not sure` and `bad image`. \n",
    "The extracted tables from [Collect Earth Online](https://collect.earth/home) contains a few information about each validation point that are originally set in the CEO tool. For monthly query of WOfS product in Africa and subsequent accuracy assessment, we need to add twelve rows corresponding to each calendar month to each validation point and then filter out those months that have duplicated labels either due to having no clear S2 observation or locating in shadow at the time of Landsat observations.\n",
    "\n",
    "This notebook explains how you can compile tables from Collect Earth Online tool from each partner institution and make them analysis-ready for WOfS analysis and accuracy assessment. \n",
    "\n",
    "The notebook demonstrates how to:\n",
    "\n",
    "1. Load collected validation points as a list of observations each has a location and month\n",
    "2. Data wrangling including cleaning the table, and mapping each point to twelve month observation \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "from datacube.utils import masking, geometry \n",
    "import sys\n",
    "import os\n",
    "import dask \n",
    "import rasterio, rasterio.features\n",
    "import xarray\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import geopandas as gpd\n",
    "import subprocess as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy, scipy.ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #this will suppress the warnings for multiple UTM zones in your AOI \n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "from deafrica_plotting import display_map, rgb\n",
    "from deafrica_spatialtools import xr_rasterize\n",
    "from deafrica_datahandling import wofs_fuser, mostcommon_crs,load_ard\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse validation points collected by each partner institution, we need to read the CEO extracted table as a dataframe and then do a few data wrangling:\n",
    "- CEO: raw table extracted from CEO tool that contains information on each validation point including the class that each analyst assigned to the point\n",
    "- ground_truth: pandas dataframe that will rename CEO table for a few columns and will be the main table for data wrangling \n",
    "- result: final table in which twelve rows have been assigned to each validation point based on the string values in water, no water, bad image and not sure columns. The value will be stored in a column called `month`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw validation points extracted from CEO tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the row validation data points csv file \n",
    "CEO = '.../Data/CEO/RCMRD/CEO_1_RCMRD_2020-07-30.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the validation data csv\n",
    "df = pd.read_csv(CEO, delimiter=\",\")\n",
    "ground_truth = df.drop(['SAMPLE_ID','USER_ID','IMAGERY_TITLE','COLLECTION_TIME','ANALYSIS_DURATION','PL_PLOTID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the columns in validation table in order to do the rename. We might experience a few distruption in cell 7. In that case, make sure, you replace the string with the correct one\n",
    "ground_truth.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the shape of the validation table \n",
    "ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth.rename(columns={'WHAT IS THE FEATURE?':'CLASS','ENTER MONTHS[1-12] IN 2018, WATER WAS OBSERVED?':'WATER',\n",
    "                                            'ENTER MONTHS[1-12] IN 2018, WATER WAS NOT OBSERVED?':'NO_WATER','ENTER MONTHS[1-12] IN 2018, IMAGE WAS BAD?':'BAD_IMAGE',\n",
    "                                             'ENTER MONTHS[1-12] IN 2018, THAT YOU ARE UNSURE IF YOU OBSERVE WATER OR NOT? ':'NOT_SURE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a picture of dataframe  \n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting column type to string if not already\n",
    "ground_truth['NOT_SURE'] = ground_truth.NOT_SURE.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making sure that the columns for each label class is string for further analysis  \n",
    "cols = ['WATER','NO_WATER','BAD_IMAGE','NOT_SURE']\n",
    "for col in cols:\n",
    "    ground_truth[col] = ground_truth[col].str.replace('[','')\n",
    "    ground_truth[col] = ground_truth[col].str.replace(']','')\n",
    "    ground_truth[col] = ground_truth[col].str.replace('&','')\n",
    "    ground_truth[col] = [''.join(c.split()) for c in ground_truth[col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the name of months with their numerical values\n",
    "replacements = { 'WATER': {r'Jan':'1', r'Feb':'2',r'Mar':'3',r'Apr':'4',r'May':'5',r'Jun':'6',r'Jul':'7',r'Aug':'8',r'Sep':'9',r'Oct':'10',r'Nov':'11',r'Dec':'12'},\n",
    "               'NO_WATER': {r'Jan':'1', r'Feb':'2',r'Mar':'3',r'Apr':'4',r'May':'5',r'Jun':'6',r'Jul':'7',r'Aug':'8',r'Sep':'9',r'Oct':'10',r'Nov':'11',r'Dec':'12'},\n",
    "               'BAD_IMAGE':{r'Jan':'1', r'Feb':'2',r'Mar':'3',r'Apr':'4',r'May':'5',r'Jun':'6',r'Jul':'7',r'Aug':'8',r'Sep':'9',r'Oct':'10',r'Nov':'11',r'Dec':'12'}}\n",
    "\n",
    "ground_truth.replace(replacements, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure that the observation time is set to 2018 in case there is a mistake in the table\n",
    "ground_truth['SENTINEL2MOSAICYEARMONTH'] = ground_truth['SENTINEL2MOSAICYEARMONTH'].str.replace('2019-2019','2018-2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to split strings in each class columns identified as `no water`, `water`, `bad image`, `not sure`.These classes will be assigned a value as 0, 1, 2, 3 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_str(row, newtable):\n",
    "#check each row for no water info and update the waterflag column \n",
    "    monthstr=row['NO_WATER']\n",
    "    if monthstr!='0'and monthstr!='nan':\n",
    "        monthlist=[[int(i) for i in s.split('-')] for s in monthstr.split(',')]\n",
    "        for l in monthlist:\n",
    "            if len(l)==1: l=[l[0],l[0]]\n",
    "            for i in range(l[0], l[1]+1):\n",
    "                newrow=row[['PLOT_ID','LON','LAT','FLAGGED','ANALYSES','WATER','NO_WATER','BAD_IMAGE','NOT_SURE','CLASS','COMMENT']]\n",
    "                newrow['MONTH']=f'{i:02d}'\n",
    "                newrow['WATERFLAG']='0'\n",
    "                newrow[\"SENTINEL2YEAR\"]='2018'\n",
    "                newtable=newtable.append(newrow) # update index / ignore original index\n",
    "#check each row for water info and update the waterflag colum \n",
    "    monthstr=row['WATER']\n",
    "    if monthstr!='0' and monthstr!='nan':\n",
    "        monthlist=[[int(i) for i in s.split('-')] for s in monthstr.split(',')]\n",
    "        for l in monthlist:\n",
    "            if len(l)==1: l=[l[0],l[0]]\n",
    "            for i in range(l[0], l[1]+1):\n",
    "                newrow=row[['PLOT_ID','LON','LAT','FLAGGED','ANALYSES','WATER','NO_WATER','BAD_IMAGE','NOT_SURE','CLASS','COMMENT']]\n",
    "                newrow['MONTH']=f'{i:02d}'\n",
    "                newrow['WATERFLAG']='1'\n",
    "                newrow[\"SENTINEL2YEAR\"]='2018'\n",
    "                newtable=newtable.append(newrow)  \n",
    "#check each row for bad image info and update the waterflag colum \n",
    "    monthstr=row['BAD_IMAGE']\n",
    "    if monthstr!='0' and monthstr!='nan':\n",
    "        monthlist=[[int(i) for i in s.split('-')] for s in monthstr.split(',')]\n",
    "        for l in monthlist:\n",
    "            if len(l)==1: l=[l[0],l[0]]\n",
    "            for i in range(l[0], l[1]+1):\n",
    "                newrow=row[['PLOT_ID','LON','LAT','FLAGGED','ANALYSES','WATER','NO_WATER','BAD_IMAGE','NOT_SURE','CLASS','COMMENT']]\n",
    "                newrow['MONTH']=f'{i:02d}'\n",
    "                newrow['WATERFLAG']='2'\n",
    "                newrow[\"SENTINEL2YEAR\"]='2018'\n",
    "                newtable=newtable.append(newrow) \n",
    "#check each row for not sure info and update the waterflag colum \n",
    "    monthstr=row['NOT_SURE']\n",
    "    if monthstr!='0' and monthstr!='nan':\n",
    "        monthlist=[[int(i) for i in s.split('-')] for s in monthstr.split(',')]\n",
    "        for l in monthlist:\n",
    "            if len(l)==1: l=[l[0],l[0]]\n",
    "            for i in range(l[0], l[1]+1):\n",
    "                newrow=row[['PLOT_ID','LON','LAT','FLAGGED','ANALYSES','WATER','NO_WATER','BAD_IMAGE','NOT_SURE','CLASS','COMMENT']]\n",
    "                newrow['MONTH']=f'{i:02d}'\n",
    "                newrow['WATERFLAG']='3'\n",
    "                newrow[\"SENTINEL2YEAR\"]='2018'\n",
    "                newtable=newtable.append(newrow) \n",
    "                \n",
    "    return newtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making an empty dataframe\n",
    "result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for irow in range(len(ground_truth)):\n",
    "    result=split_str(ground_truth.iloc[irow], result)\n",
    "    result.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape\n",
    "result.loc[13]#this shows part of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = result[result.duplicated(['LAT', 'LON','MONTH'], keep=False)]\n",
    "indexNames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[['PLOT_ID', 'LON', 'LAT','FLAGGED','ANALYSES','SENTINEL2YEAR', 'WATER','NO_WATER','BAD_IMAGE','NOT_SURE','CLASS', 'COMMENT', 'MONTH','WATERFLAG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final table that has Waterflags identified based on the lables from Analysts\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe as csv file \n",
    "result.to_csv('../Data/Processed/RCMRD/CEO_1_RCMRD_2020-07-30.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell should be run following inspecting all subprojects for each partner institutions in order to join all tables into one for each partner institutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining dataframes together and extract one csv for each partner institution \n",
    "DF = glob.glob('../Supplementary_data/Validation/Refined/*_RCMRD_*.csv')\n",
    "frame = []\n",
    "for d in DF: \n",
    "    f = pd.read_csv(d,delimiter=\",\")\n",
    "    frame.append(f)\n",
    "out = pd.concat(frame)\n",
    "out.to_csv('../Data/Processed/RCMRD/RCMRD_ValidationPoints.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** January 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DE Africa User Guide's [Tags Index](https://) (placeholder as this does not exist yet)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**:  :index:`WOfS`, :index:`fractional cover`, :index:`deafrica_plotting`, :index:`deafrica_datahandling`, :index:`display_map`, :index:`wofs_fuser`, :index:`WOFL`, :index:`masking`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "9e3fa49adf8c4170abfcd954c2ec045a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "dc642f11c1fb492ca419b0ed6fc4f8c3": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
